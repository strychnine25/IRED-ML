{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START\n",
    "The first cell below must always be run, regardless of if the pickle has already been created or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bio_embeddings.embed import # embedder of choice\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP\n",
    "Only run the cells below (until next markdown cell) if the sequences are being embedded with the embedder of choice. First make sure the 'embedder of choice' comment has been ammended before running, in addition to changing the file names for reading the excel file and subsequently saving the embedded data into a pickle. <br>\n",
    "Scroll down to 'Resume' if you are intending to open a pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the requisite excel file into pandas dataframe. First two entries of the df are printed to check data is correct\n",
    "df = pd.read_excel('File name.xlsx', engine='openpyxl')\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially making a copy of the dataframe, then dropping entries which do not contain a value in the enantiomer column\n",
    "# The shape is then checked to see how many entries remain\n",
    "df = df.copy()\n",
    "df.dropna(subset=['Enantiomer'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using bioembeddings to embed the protein sequences, and saving the output data into a pickle file as it is a lengthy\n",
    "# process to run the code (25 mins). The pickle file can be opened (vide infra) in the future to access the embeddings.\n",
    "# DO NOT RUN\n",
    "embedder = # embedder of choice()\n",
    "df['embedding'] = df['Sequence'].progress_apply(embedder.embed)\n",
    "df['em_per_protein'] = df['embedding'].progress_apply(embedder.reduce_per_protein)\n",
    "\n",
    "df.to_pickle('File name.pkl')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESUME\n",
    "In all instances where random_state is an argument, ensure the **same integer** is maintained for reproducibility purposes. <br> N.b. integer = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=25\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, log_loss, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(rc={'figure.figsize': (10, 10)})\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_theme()\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('File name.pkl')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df['em_per_protein'])\n",
    "y = df['enantiomer binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets, remember the random_state argument!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA analysis\n",
    "Quick check for correlation between R and S selective sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "crds = pca.fit_transform(list(df['em_per_protein']))\n",
    "\n",
    "pca_df = pd.DataFrame(crds, columns=['x', 'y'])\n",
    "\n",
    "df['x'] = pca_df['x']\n",
    "df['y'] = pca_df['y']\n",
    "ax = sns.scatterplot(data=df, x='x', y='y', hue='Enantiomer', style='Enantiomer', s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbours (k-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "knn_accuracy = knn.score(X_test, y_test)\n",
    "knn_f1 = f1_score(y_test, y_pred_knn)\n",
    "knn_logloss = log_loss(y_test, y_pred_knn)\n",
    "\n",
    "print('The knn accuracy is {:.3f}'.format(knn_accuracy));\n",
    "print('The knn f1 score is {:.3f}'.format(knn_f1));\n",
    "print('The knn log loss is {:.3f}'.format(knn_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_knn = knn.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_scores_knn[:,1])\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.plot(fpr, tpr, label='AUC = %0.2f' %roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('k-NN ROC curve')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv_scores = cross_val_score(knn, X, y, cv=10, scoring='f1')\n",
    "knn_cv_mean = knn_cv_scores.mean()\n",
    "knn_cv_std = knn_cv_scores.std()\n",
    "print('The k-NN cross-validation mean is {:.3f}'.format(knn_cv_mean));\n",
    "print('The k-NN cross-validation standard deviation is {:.3f}'.format(knn_cv_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "\n",
    "logreg_accuracy = knn.score(X_test, y_test)\n",
    "logreg_f1 = f1_score(y_test, y_pred_logreg)\n",
    "logreg_logloss = log_loss(y_test, y_pred_logreg)\n",
    "\n",
    "print('The Logistic Regression accuracy is {:.3f}'.format(logreg_accuracy));\n",
    "print('The Logistic Regression f1 score is {:.3f}'.format(logreg_f1));\n",
    "print('The Logistic Regression log loss is {:.3f}'.format(logreg_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_logreg = logreg.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_scores_logreg[:,1])\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.plot(fpr, tpr, label='AUC = %0.2f' %roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC curve')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_cv_scores = cross_val_score(logreg, X, y, cv=10, scoring='f1')\n",
    "logreg_cv_mean = logreg_cv_scores.mean()\n",
    "logreg_cv_std = logreg_cv_scores.std()\n",
    "print('The Logistic Regression cross-validation mean is {:.3f}'.format(logreg_cv_mean));\n",
    "print('The Logistic Regression cross-validation standard deviation is {:.3f}'.format(logreg_cv_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=SEED)\n",
    "knn = KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "classifiers = [('Logistic Regression', lr),('K Nearest Neighbours', knn),('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_soft = VotingClassifier(estimators=classifiers, voting='soft')\n",
    "vc_soft.fit(X_train, y_train)\n",
    "y_pred_soft = vc_soft.predict(X_test)\n",
    "\n",
    "vc_soft_accuracy = vc_soft.score(X_test, y_test)\n",
    "vc_soft_f1 = f1_score(y_test, y_pred_soft)\n",
    "vc_soft_logloss = log_loss(y_test, y_pred_soft)\n",
    "\n",
    "print('The Voting Classifier (soft) accuracy is {:.3f}'.format(vc_soft_accuracy));\n",
    "print('The Voting Classifier (soft) f1 score is {:.3f}'.format(vc_soft_f1));\n",
    "print('The Voting Classifier (soft) log loss is {:.3f}'.format(vc_soft_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_soft = vc_soft.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_scores_soft[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "y_pred_prob = vc_soft.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr, label='AUC = %0.2f' %roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Voting Classifier ensemble ROC curve')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_cv_scores = cross_val_score(vc_soft, X, y, cv=10, scoring='f1')\n",
    "soft_cv_mean = soft_cv_scores.mean()\n",
    "soft_cv_std = soft_cv_scores.std()\n",
    "print('The Voting Classifier (soft) cross-validation mean is {:.3f}'.format(soft_cv_mean));\n",
    "print('The Voting Classifier (soft) cross-validation standard deviation is {:.3f}'.format(soft_cv_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_hard = VotingClassifier(estimators=classifiers, voting='hard')\n",
    "vc_hard.fit(X_train, y_train)\n",
    "y_pred_hard = vc_hard.predict(X_test)\n",
    "\n",
    "vc_hard_accuracy = vc_soft.score(X_test, y_test)\n",
    "vc_hard_f1 = f1_score(y_test, y_pred_hard)\n",
    "vc_hard_logloss = log_loss(y_test, y_pred_hard)\n",
    "\n",
    "print('The Voting Classifier (hard) accuracy is {:.3f}'.format(vc_hard_accuracy));\n",
    "print('The Voting Classifier (hard) f1 score is {:.3f}'.format(vc_hard_f1));\n",
    "print('The Voting Classifier (hard) log loss is {:.3f}'.format(vc_hard_logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_cv_scores = cross_val_score(vc_hard, X, y, cv=10, scoring='f1')\n",
    "hard_cv_mean = hard_cv_scores.mean()\n",
    "hard_cv_std = hard_cv_scores.std()\n",
    "print('The Voting Classifier (hard) cross-validation mean is {:.3f}'.format(hard_cv_mean));\n",
    "print('The Voting Classifier (hard) cross-validation standard deviation is {:.3f}'.format(hard_cv_std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
